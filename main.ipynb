{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"qtRAFaU-RsZ-"},"source":["# mount drive, install kaggle, download the data, and unzip\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","!pip install -q kaggle\n","%mkdir /root/.kaggle\n","%cp /content/gdrive/My\\ Drive/CMU11785-HW2P2/kaggle.json  /root/.kaggle/\n","%cd /\n","!kaggle datasets download -d cmu11785/20fall-hw2p2\n","!unzip -q 20fall-hw2p2.zip -d data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lBnd-4bElmIH"},"source":["# change directory to hw2_p2\n","%cd /content/gdrive/My\\ Drive/CMU11785-HW2P2/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ArT3mZm7sX5X"},"source":["# importing the packages\n","import os\n","import numpy as np\n","from PIL import Image\n","import time\n","import datetime\n","import torch.optim as optim\n","import torch\n","from torchvision import transforms, datasets\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import roc_auc_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NyNw9NEYxxs3"},"source":["#smallest ResNET Block\n","class baseBlock(torch.nn.Module):\n","  def __init__(self,in_channel,out_channel,stride=1,shortcut=None):\n","      super(baseBlock,self).__init__()\n","      self.conv1 = torch.nn.Conv2d(in_channel,out_channel,stride=stride,kernel_size=3,padding=1)\n","      self.bn1   = torch.nn.BatchNorm2d(out_channel)\n","      self.conv2 = torch.nn.Conv2d(out_channel,out_channel,stride=1,kernel_size=3,padding=1)\n","      self.bn2   = torch.nn.BatchNorm2d(out_channel)\n","      self.shortcut = shortcut\n","\n","  def forward(self,x):\n","      output = F.relu(self.bn1(self.conv1(x)))\n","      #print(output.shape)\n","      output = self.bn2(self.conv2(output))\n","      #print(output.shape)\n","      if self.shortcut is not None:\n","        output += self.shortcut(x)\n","      output = F.relu(output)\n","      #print(output.shape)\n","      return output\n","\n","\n","class ResNet(torch.nn.Module):\n","  def __init__(self,num_layers,classes=10,feats=512):\n","      super(ResNet,self).__init__()\n","      self.conv1 = nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1)\n","      self.bn1   = nn.BatchNorm2d(64)\n","      self.input_planes = 64\n","      self.layer1 = self._layer(64,  num_layers[0],stride=2)\n","      self.layer2 = self._layer(128,  num_layers[1],stride=2)\n","      self.layer3 = self._layer(256,  num_layers[2],stride=2)\n","      self.layer4 = self._layer(feats,num_layers[3],stride=2)\n","      self.avgPool = nn.AdaptiveAvgPool2d((2))\n","      self.fc  =  torch.nn.Linear(feats*2*2,classes)\n","  \n","  def _layer(self,planes,num_layers,stride=1):\n","      netLayers =[]\n","      shortcut = None\n","      if stride !=1 or self.input_planes != planes:\n","        shortcut = torch.nn.Sequential(torch.nn.Conv2d(self.input_planes,planes,kernel_size=1,stride=stride),\n","                        torch.nn.BatchNorm2d(planes))\n","      \n","      netLayers.append(baseBlock(self.input_planes,planes,stride=stride,shortcut=shortcut))\n","      self.input_planes = planes\n","      for i in range(1,num_layers):\n","          netLayers.append(baseBlock(self.input_planes,planes))\n","          self.input_planes = planes\n","      return torch.nn.Sequential(*netLayers)\n","\n","  def forward(self,x):\n","      x = F.relu(self.bn1(self.conv1(x)))\n","      #print(\"Conv1  :\",x.shape)\n","      x = self.layer1(x)\n","      #print(\"L_1:\",x.shape)\n","      x = self.layer2(x)\n","      #print(\"L_2:\",x.shape)\n","      x = self.layer3(x)\n","      #print(\"L_3:\",x.shape)\n","      x = self.layer4(x)\n","      #print(\"L_4:\",x.shape)\n","      x = self.avgPool(x)\n","      #print(\"avg:\",x.shape)\n","      x = torch.flatten(x,1)\n","      #print(\"flattened:\",x.shape)\n","      out =self.fc(x)\n","      #print(\"labels: \",x.shape)\n","      return x,out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dbbjiEDWJpqc"},"source":["x= torch.randn(5,3,64,64)\n","feats,out = ResNet([1,1,1,1],4000,512)(x)\n","print(out.shape)\n","print(feats.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CzaAMUvfTBnx"},"source":["def init_weights(m):\n","  if type(m) == nn.Conv2d:    \n","    nn.init.kaiming_normal_(m.weight)\n","    if m.bias is not None:\n","      nn.init.zeros_(m.bias)\n","      \n","  if type(m) == nn.Linear:\n","    nn.init.xavier_normal_(m.weight)\n","\n","  if type(m) == nn.BatchNorm2d:\n","    nn.init.ones_(m.weight)\n","    nn.init.zeros_(m.bias)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVJYtSy_y3iD"},"source":["def save_model(net,epoch):\n","  current_time = datetime.datetime.now().strftime(\"%m.%d\")\n","  # Specify a path\n","  newDir(\"saved_model_with_centloss\")\n","  PATH = os.getcwd()+f\"/saved_model_with_centloss/state_dict_model_{current_time}_{epoch}.pt\"\n","  print(\"----------- saving the model ....\\n\") \n","  torch.save(net.state_dict(), PATH)\n","\n","\n","\n","def save_output(vector,name):\n","  current_time = datetime.datetime.now().strftime(\"%Y.%m.%d-%H:%M:%S\")\n","  print(\" Saving outputs ...\")\n","  newDir('output_cent')\n","  PATH  = os.getcwd()+\"/output_cent/\"\n","  np.save(PATH+ f'{name}_{current_time}.npy',vector)\n","\n","\n","def visualize(soln_vect,name):\n","# from HW1_P1\n","  print(f\"Saving graphs for \\\"{name}\\\"\")\n","  newDir('output_cent')\n","  current_time = datetime.datetime.now().strftime(\"%Y.%m.%d-%H:%M:%S\")\n","  PATH = os.getcwd() + \"/output_cent/\"\n","  try :\n","    plt.plot(soln_vect)\n","    plt.ylabel(name)\n","    plt.savefig(PATH +f\"{name}_{current_time}.png\")\n","  except Exception as e:\n","    traceback.print_exc()\n","    print(\"Error: Problems generating plots. See if a .png was generated in output folder\\n\")\n","\n","\n","class newDir:\n","  def __init__(self,name):\n","    self.name = name\n","    if not os.path.exists(name):\n","        os.mkdir(name)\n","        print(f\"{self.name} directory created! \")\n","    else :\n","        print(f\"{self.name} directory exists! \")\n","\n","class rmDir:\n","  def __init__(self,name):\n","    self.name = name\n","    if os.path.exists(name):\n","      os.rmdir(name)\n","      print(f\"{self.name} directory is removed! \")\n","    else :\n","      print(f\"{self.name} directory does not exist! \")\n","\n","\n","def get_myDataset(data_dir,train=False,val=False,test=False):\n","  transform_kwargs = {\n","\t\t'train': transforms.Compose([transforms.RandomHorizontalFlip(),\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))]),\n","\n","\t\t'val'  : transforms.Compose([transforms.ToTensor(),\n","                        transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))]),\n","\t\n","\t\t'test' : transforms.Compose([transforms.ToTensor(),\n","                         transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))])\n","\t\t\t}\n","  if train:\n","    root \t  = os.path.join(data_dir,'train_data/')\n","    transform = transform_kwargs['train']\n","  if val :\n","    root      = os.path.join(data_dir,'val_data/')\n","\t\t#print(\"root: \",root)\n","    transform = transform_kwargs['val']\n","  if test:\n","    root \t  = os.path.join(data_dir,'test_data/')\n","    transform = transform_kwargs['test']\n","  data_set = datasets.ImageFolder(root=root, transform = transform)\n","  return data_set\n","\n","\n","def get_data_loader(data_set,**kwargs):\n","\treturn torch.utils.data.DataLoader(dataset=data_set,**kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ogg4F_2YVD__"},"source":["def train_with_center_loss(model,train_loader,criterion_xent,criterion_cent,\n","          optimizer_label,optimizer_cent,weight_cent,device):\n","  model.train()\n","  running_loss = 0.0\n","  for batch_index,(data, target) in enumerate(train_loader):   \n","    data = data.to(device)\n","    target = target.to(device) \n","    embeddings, labels = model(data)\n","    loss_xent = criterion_xent(labels,target)\n","    loss_cent = criterion_cent(embeddings,target)\n","    loss = loss_xent + weight_cent*loss_cent\n","    optimizer_label.zero_grad()\n","    optimizer_cent.zero_grad()\n","    loss.backward()\n","    optimizer_label.step()\n","     \n","    for param in criterion_cent.parameters():\n","      param.grad.data *=(1./weight_cent)\n","\n","    optimizer_cent.step()\n","    running_loss +=loss\n","    torch.cuda.empty_cache()\n","    del target\n","    del data\n","    if (batch_index+1) % 1000 == 0:\n","      print('Batch_index : {:5d}, Average training Loss/Batch: {:4.4f}'.format(batch_index+1, running_loss/1000))\n","      running_loss = 0.0\n","  return running_loss          "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BldhcOqrVyY1"},"source":["def test_with_center_loss(model, test_loader,criterion_xent,criterion_cent, weight_cent,device):  \n","  with torch.no_grad():\n","    model.eval()\n","    running_loss = 0.0\n","    total_predictions = 0.0\n","    correct_predictions = 0.0\n","    start_time = time.time()\n","    for data, target in test_loader:\n","      data = data.to(device)\n","      target = target.to(device) \n","      embeddings, labels = model(data)   \n","      loss_xent = criterion_xent(labels,target)\n","      loss_cent = criterion_cent(embeddings,target) \n","      loss = loss_xent + weight_cent*loss_cent\n","      running_loss +=loss\n","      _, predicted = torch.max(F.softmax(labels.data,dim=1), 1)\n","      predicted    = predicted.view(-1) \n","      total_predictions += len(target)     \n","      correct_predictions += (predicted == target).sum().item()\n","\n","      torch.cuda.empty_cache()\n","      del data \n","      del target    \n","\n","    end_time = time.time()   \n","    running_loss /= len(test_loader)   \n","    acc = (correct_predictions/total_predictions)*100.0   \n","    print('Testing Loss: {:2.2e}'.format(running_loss))    \n","    print('Testing Accuracy: {:2.2f}%, Time: {:4.3f}  Sec'.format(acc,end_time - start_time))   \n","    return running_loss, acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3D6bJm0CWRH_"},"source":["class CenterLoss(nn.Module):\n","  \"\"\"\n","  From Recition 6\n","  Args:\n","      num_classes (int): number of classes.\n","      feat_dim (int): feature dimension.\n","  \"\"\"\n","  def __init__(self, num_classes, feat_dim, device=torch.device('cpu')):   \n","      super(CenterLoss, self).__init__()\n","      self.num_classes = num_classes  \n","      self.feat_dim = feat_dim\n","      self.device = device \n","      self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).to(self.device))\n","\n","  def forward(self, x, labels):\n","      \"\"\"\n","      Args:\n","          x: feature matrix with shape (batch_size, feat_dim).\n","          labels: ground truth labels with shape (batch_size).\n","      \"\"\"\n","      batch_size = x.size(0)  \n","      distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n","                torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n","      distmat.addmm_(1, -2, x, self.centers.t())\n","      classes = torch.arange(self.num_classes).long().to(self.device)    \n","      labels = labels.unsqueeze(1).expand(batch_size, self.num_classes) \n","      mask = labels.eq(classes.expand(batch_size, self.num_classes))\n","      dist = []\n","      for i in range(batch_size):   \n","          value = distmat[i][mask[i]]     \n","          value = value.clamp(min=1e-12, max=1e+12) # for numerical stability     \n","          dist.append(value)    \n","      dist = torch.cat(dist)     \n","      loss = dist.mean()\n","      return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LqyIRLwcZ5mA","executionInfo":{"status":"ok","timestamp":1603395132022,"user_tz":240,"elapsed":394,"user":{"displayName":"shams basir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8NJWd8PZvQ1q4IT0m-PJSHWn2nLzMCOXym7Ydiw=s64","userId":"09640498298136079307"}}},"source":["class fetch_image_pairs(torch.utils.data.Dataset):\n","  def __init__(self,text_pair_path,dir_path,dev_pair=False):\n","   self.pair_1  = []\n","   self.pair_2  = []\n","   self.label   = []\n","   self.dev_pair = dev_pair\n","   self.dir_path = dir_path\n","\n","   with open(text_pair_path) as f:\n","     for line in f:\n","       items = line.split()\n","       self.pair_1.append(items[0])\n","       self.pair_2.append(items[1])\n","       if self.dev_pair:\n","         self.label.append(items[2])\n","       else:\n","          self.label.append(-1)\n","\n","  def __len__(self):\n","    return len(self.pair_1)\n","  \n","  def __getitem__(self,index):\n","    img1 = Image.open(self.dir_path+self.pair_1[index])\n","    img2 = Image.open(self.dir_path+self.pair_2[index])\n","    img1 = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))])(img1)\n","    img2 = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))])(img2)\n","    lbl = int(self.label[index])\n","    return img1,img2,lbl\n","\n","\n","def test_verify(model,vpv_loader):\n","  sim_score   = []\n","  exact_score = []\n","  tart_time = time.time()\n","  with torch.no_grad():\n","    model.eval()\n","    for batch_idx, (img1,img2,true_score) in enumerate(vpv_loader):  \n","      img1,img2,true_score = img1.to(device), img2.to(device),true_score.to(device)\n","      embedding_1 = model(img1.float())[0]\n","      embedding_2 = model(img2.float())[0]\n","      calc_score = F.cosine_similarity(embedding_1,embedding_2)\n","      #print(\"calc_score.shape: \",calc_score.shape)\n","      #print(\"true_score.shape: \",true_score.shape)\n","      sim_score.append(calc_score.view(-1))\n","      exact_score.append(true_score.view(-1))\n","      torch.cuda.empty_cache()\n","      del true_score\n","      del img1\n","      del img2\n","  end_time = time.time()\n","  print(\"Similarity score calculated:!\")\n","  return sim_score,exact_score"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"id":"RAWBUbLgFkTs"},"source":["# Hyper parameters\n","cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","train_batch_size = 128                      # input batch size for training')\n","test_batch_size  = 64                       # input batch size for training')\n","epochs           = 1                       # number of epochs for training\n","base_lr          = 5.52e-03                 # learning rate for a single GPU\n","lr_cent          = 0.5                      # learning rate for center Loss\n","weight_cent      = 0.15                    # Weight of the Center Loss\n","wd               = 5.0e-04                  # weight decay\n","num_workers      = 4                        # number of worksers for GPU\n","momentum         = 0.9                      # SGD momentum\n","embedding_dim    = 512                      # embedding dimension for images\n","hidden_layers    = [1,1,1,1]                # ResNET hidden Layers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xCG7dglRFd_j"},"source":["data_dir = \"/data/classification_data/\"; \n","dev_set = get_myDataset(data_dir,train=False,val=True,test=False)\n","kwargs=dict(shuffle=False,batch_size=test_batch_size,num_workers=num_workers,pin_memory=True,drop_last=False)\n","dev_loader = get_data_loader(dev_set,**kwargs)\n","print(len(dev_set))\n","\n","train_set = get_myDataset(data_dir,train=True,val=False,test=False)\n","kwargs=dict(shuffle=True,batch_size=train_batch_size,num_workers=num_workers,pin_memory=True,drop_last=False)\n","train_loader = get_data_loader(train_set,**kwargs)\n","print(len(train_set))\n","\n","# Now estimating the AUC for the validation pairs\n","vpv_set    = fetch_image_pairs('/data/verification_pairs_val.txt',\"/data/\",dev_pair=True)\n","vpv_loader = DataLoader(vpv_set,batch_size=test_batch_size,shuffle=False,num_workers=num_workers,drop_last=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"riJY7K7Yye-y","executionInfo":{"status":"ok","timestamp":1603393317081,"user_tz":240,"elapsed":605,"user":{"displayName":"shams basir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8NJWd8PZvQ1q4IT0m-PJSHWn2nLzMCOXym7Ydiw=s64","userId":"09640498298136079307"}},"outputId":"a314d655-e608-4ca5-eff1-dc0f2fe9226b","colab":{"base_uri":"https://localhost:8080/","height":935}},"source":["# Model \n","num_classes      = len(train_set.classes)      # number of unique classes\n","model = ResNet(hidden_layers,num_classes,embedding_dim)\n","PATH  = os.getcwd()+f\"/saved_model_with_centloss/state_dict_model_10.22_4.pt\"\n","model.load_state_dict(torch.load(PATH))\n","#model.apply(init_weights)\n","\n","criterion_xent = nn.CrossEntropyLoss()\n","criterion_cent = CenterLoss(num_classes,embedding_dim*4,device)\n","\n","optimizer_label = torch.optim.SGD(model.parameters(),lr=base_lr,momentum = momentum,weight_decay=wd,nesterov=True)\n","optimizer_cent  = torch.optim.SGD(criterion_cent.parameters(),lr=lr_cent,momentum=momentum,weight_decay=wd,nesterov=True)\n","\n","scheduler =torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_label, mode='min', factor=0.85,\n","                                           patience=2, threshold=0.5, \n","                                           threshold_mode='rel', cooldown=0, \n","                                           min_lr=0, eps=1e-04, \n","                                           verbose=True)\n","model.to(device)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (layer1): Sequential(\n","    (0): baseBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): baseBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): baseBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): baseBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (avgPool): AdaptiveAvgPool2d(output_size=2)\n","  (fc): Linear(in_features=2048, out_features=4000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"UvfB9AfAyx2x"},"source":["Train_loss = []\n","Test_loss  = []\n","Test_acc   = []\n","print('*-*'*20)\n","print('train_batch_size: {}, test_batch_size: {}'.format(train_batch_size,test_batch_size))\n","print('*-*'*20)\n","print('Epoch : {:2d}, Learning rate : {:.2e} ' .format(1,optimizer_label.param_groups[0]['lr']))\n","for epoch in range(epochs):\n","  train_loss = train_with_center_loss(model,train_loader,\n","                                      criterion_xent,criterion_cent,\n","                                      optimizer_label,optimizer_cent,\n","                                      weight_cent,device)\n","\n","  test_loss, test_acc =test_with_center_loss(model, dev_loader,\n","                                             criterion_xent,criterion_cent, \n","                                             weight_cent,device)\n","  Train_loss.append(train_loss)\n","  Test_loss.append(test_loss)\n","  Test_acc.append(test_acc)\n","  sim_score,exact_score=test_verify(model,vpv_loader)\n","  sim_score = torch.cat(sim_score,axis=0)\n","  exact_score = torch.cat(exact_score,axis=0)\n","  auc   = roc_auc_score(exact_score.cpu().numpy(),sim_score.cpu().numpy())\n","  print('='*20)\n","  print('*auc: {:.3f}'.format(auc))\n","  print('*^*'*20)\n","  scheduler.step(test_loss)\n","  save_model(model,epoch)\n","  print('Epoch : {:2d}, Learning rate : {:.2e} ' .format(epoch+1,optimizer_label.param_groups[0]['lr']))\n","save_output(Train_loss,'Train_loss')\n","save_output(Test_loss,'Test_loss')\n","save_output(Test_acc,'Test_acc')\n","visualize(Train_loss,'Train_loss')\n","visualize(Test_loss,'Test_loss')\n","visualize(Test_acc,'Test_acc') "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OmcQA5dFr7NI","executionInfo":{"status":"ok","timestamp":1603393337142,"user_tz":240,"elapsed":7267,"user":{"displayName":"shams basir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8NJWd8PZvQ1q4IT0m-PJSHWn2nLzMCOXym7Ydiw=s64","userId":"09640498298136079307"}},"outputId":"a94f0675-ff59-42bb-c8a0-adab2d72caa5","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["  model.eval()\n","  sim_score,exact_score=test_verify(model,vpv_loader)\n","  sim_score = torch.cat(sim_score,axis=0)\n","  exact_score = torch.cat(exact_score,axis=0)\n","  auc   = roc_auc_score(exact_score.cpu().numpy(),sim_score.cpu().numpy())\n","  print('='*20)\n","  print('*auc: {:.3f}'.format(auc))\n","  print('*^*'*20)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Similarity score calculated:!\n","====================\n","*auc: 0.941\n","*^**^**^**^**^**^**^**^**^**^**^**^**^**^**^**^**^**^**^**^*\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AcNz7f_Uu6zT"},"source":[""],"execution_count":null,"outputs":[]}]}